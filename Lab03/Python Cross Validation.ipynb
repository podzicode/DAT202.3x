{"nbformat_minor": 1, "cells": [{"source": "## Using Cross Validation\n\nIn this exercise, you will use cross-validation to optimize parameters for a regression model.\n\n### Prepare the Data\n\nFirst, import the libraries you will need and prepare the training and test data:", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "# Import Spark SQL and Spark ML libraries\nfrom pyspark.sql.types import *\nfrom pyspark.sql.functions import *\n\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.regression import LinearRegression\nfrom pyspark.ml.feature import VectorAssembler\nfrom pyspark.ml.tuning import ParamGridBuilder, CrossValidator\nfrom pyspark.ml.evaluation import RegressionEvaluator\n\n# Load the source data\ncsv = spark.read.csv('wasb:///data/flights.csv', inferSchema=True, header=True)\n\n# Select features and label\ndata = csv.select(\"DayofMonth\", \"DayOfWeek\", \"OriginAirportID\", \"DestAirportID\", \"DepDelay\", col(\"ArrDelay\").alias(\"label\"))\n\n# Split the data\nsplits = data.randomSplit([0.7, 0.3])\ntrain = splits[0]\ntest = splits[1].withColumnRenamed(\"label\", \"trueLabel\")", "outputs": [], "metadata": {"scrolled": false, "collapsed": false}}, {"source": "### Define the Pipeline\nNow define a pipeline that creates a feature vector and trains a regression model", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "# Define the pipeline\nassembler = VectorAssembler(inputCols = [\"DayofMonth\", \"DayOfWeek\", \"OriginAirportID\", \"DestAirportID\", \"DepDelay\"], outputCol=\"features\")\nlr = LinearRegression(labelCol=\"label\",featuresCol=\"features\")\npipeline = Pipeline(stages=[assembler, lr])", "outputs": [], "metadata": {"scrolled": false, "collapsed": false}}, {"source": "### Tune Parameters\nYou can tune parameters to find the best model for your data. To do this you can use the  **CrossValidator** class to evaluate each combination of parameters defined in a **ParameterGrid** against multiple *folds* of the data split into training and validation datasets, in order to find the best performing parameters. Note that this can take a long time to run because every parameter combination is tried multiple times.", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "paramGrid = ParamGridBuilder().addGrid(lr.regParam, [0.3, 0.01]).addGrid(lr.maxIter, [10, 5]).build()\ncv = CrossValidator(estimator=pipeline, evaluator=RegressionEvaluator(), estimatorParamMaps=paramGrid, numFolds=2)\n\nmodel = cv.fit(train)", "outputs": [], "metadata": {"collapsed": false}}, {"source": "### Test the Model\nNow you're ready to apply the model to the test data.", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "prediction = model.transform(test)\npredicted = prediction.select(\"features\", \"prediction\", \"trueLabel\")\npredicted.show()", "outputs": [], "metadata": {"scrolled": false, "collapsed": false}}, {"source": "### Examine the Predicted and Actual Values\nYou can plot the predicted values against the actual values to see how accurately the model has predicted. In a perfect model, the resulting scatter plot should form a perfect diagonal line with each predicted value being identical to the actual value - in practice, some variance is to be expected.\nRun the cells below to create a temporary table from the **predicted** DataFrame and then retrieve the predicted and actual label values using SQL. You can then display the results as a scatter plot, specifying **-** as the function to show the unaggregated values.", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "predicted.createOrReplaceTempView(\"regressionPredictions\")", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "%%sql\nSELECT trueLabel, prediction FROM regressionPredictions", "outputs": [], "metadata": {"collapsed": false}}, {"source": "### Retrieve the Root Mean Square Error (RMSE)\nThere are a number of metrics used to measure the variance between predicted and actual values. Of these, the root mean square error (RMSE) is a commonly used value that is measured in the same units as the prediced and actual values - so in this case, the RMSE indicates the average number of minutes between predicted and actual flight delay values. You can use the **RegressionEvaluator** class to retrieve the RMSE.\n", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "evaluator = RegressionEvaluator(labelCol=\"trueLabel\", predictionCol=\"prediction\", metricName=\"rmse\")\nrmse = evaluator.evaluate(prediction)\nprint \"Root Mean Square Error (RMSE):\", rmse", "outputs": [], "metadata": {"collapsed": false}}], "nbformat": 4, "metadata": {"kernelspec": {"display_name": "PySpark", "name": "pysparkkernel", "language": ""}, "language_info": {"mimetype": "text/x-python", "pygments_lexer": "python2", "name": "pyspark", "codemirror_mode": {"version": 2, "name": "python"}}}}