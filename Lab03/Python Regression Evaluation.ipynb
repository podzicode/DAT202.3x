{"nbformat_minor": 1, "cells": [{"source": "## Evaluating a Regression Model\n\nIn this exercise, you will create a pipeline for a linear regression model, and then test and evaluate the model.\n\n### Prepare the Data\n\nFirst, import the libraries you will need and prepare the training and test data:", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "# Import Spark SQL and Spark ML libraries\nfrom pyspark.sql.types import *\nfrom pyspark.sql.functions import *\n\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.regression import LinearRegression\nfrom pyspark.ml.feature import VectorAssembler\n\n# Load the source data\ncsv = spark.read.csv('wasb:///data/flights.csv', inferSchema=True, header=True)\n\n# Select features and label\ndata = csv.select(\"DayofMonth\", \"DayOfWeek\", \"OriginAirportID\", \"DestAirportID\", \"DepDelay\", col(\"ArrDelay\").alias(\"label\"))\n\n# Split the data\nsplits = data.randomSplit([0.7, 0.3])\ntrain = splits[0]\ntest = splits[1].withColumnRenamed(\"label\", \"trueLabel\")", "outputs": [], "metadata": {"scrolled": false, "collapsed": false}}, {"source": "### Define the Pipeline and Train the Model\nNow define a pipeline that creates a feature vector and trains a regression model", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "# Define the pipeline\nassembler = VectorAssembler(inputCols = [\"DayofMonth\", \"DayOfWeek\", \"OriginAirportID\", \"DestAirportID\", \"DepDelay\"], outputCol=\"features\")\nlr = LinearRegression(labelCol=\"label\",featuresCol=\"features\", maxIter=10, regParam=0.3)\npipeline = Pipeline(stages=[assembler, lr])\n\n# Train the model\npiplineModel = pipeline.fit(train)", "outputs": [], "metadata": {"scrolled": false, "collapsed": false}}, {"source": "### Test the Model\nNow you're ready to apply the model to the test data.", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "prediction = piplineModel.transform(test)\npredicted = prediction.select(\"features\", \"prediction\", \"trueLabel\")\npredicted.show()", "outputs": [], "metadata": {"scrolled": false, "collapsed": false}}, {"source": "### Examine the Predicted and Actual Values\nYou can plot the predicted values against the actual values to see how accurately the model has predicted. In a perfect model, the resulting scatter plot should form a perfect diagonal line with each predicted value being identical to the actual value - in practice, some variance is to be expected.\nRun the cells below to create a temporary table from the **predicted** DataFrame and then retrieve the predicted and actual label values using SQL. You can then display the results as a scatter plot, specifying **-** as the function to show the unaggregated values.", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "predicted.createOrReplaceTempView(\"regressionPredictions\")", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "%%sql\nSELECT trueLabel, prediction FROM regressionPredictions", "outputs": [], "metadata": {"collapsed": false}}, {"source": "### Retrieve the Root Mean Square Error (RMSE)\nThere are a number of metrics used to measure the variance between predicted and actual values. Of these, the root mean square error (RMSE) is a commonly used value that is measured in the same units as the predicted and actual values - so in this case, the RMSE indicates the average number of minutes between predicted and actual flight delay values. You can use the **RegressionEvaluator** class to retrieve the RMSE.\n", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "from pyspark.ml.evaluation import RegressionEvaluator\n\nevaluator = RegressionEvaluator(labelCol=\"trueLabel\", predictionCol=\"prediction\", metricName=\"rmse\")\nrmse = evaluator.evaluate(prediction)\nprint \"Root Mean Square Error (RMSE):\", rmse", "outputs": [], "metadata": {"collapsed": false}}], "nbformat": 4, "metadata": {"kernelspec": {"display_name": "PySpark", "name": "pysparkkernel", "language": ""}, "widgets": {"state": {"d6eefac808724429915e0b32eea703c9": {"views": [{"cell_index": 8}]}, "3cc3b0402bc44842aed785220d307db0": {"views": [{"cell_index": 8}]}, "76bc6e0b425942c3bf1e45506e6ed087": {"views": [{"cell_index": 8}]}, "9a621f8e3bc242bb8ca31f76cc02b5da": {"views": [{"cell_index": 8}]}}, "version": "1.2.0"}, "language_info": {"mimetype": "text/x-python", "pygments_lexer": "python2", "name": "pyspark", "codemirror_mode": {"version": 2, "name": "python"}}}}