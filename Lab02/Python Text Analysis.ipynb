{"nbformat_minor": 1, "cells": [{"source": "## Text Analysis\nIn this lab, you will create a classification model that performs sentiment analysis of tweets.\n### Import Spark SQL and Spark ML Libraries\n\nFirst, import the libraries you will need:", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "from pyspark.sql.types import *\nfrom pyspark.sql.functions import *\n\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.classification import LogisticRegression\nfrom pyspark.ml.feature import HashingTF, Tokenizer, StopWordsRemover", "outputs": [], "metadata": {"scrolled": false, "collapsed": false}}, {"source": "### Load Source Data\nNow load the tweets data into a DataFrame. This data consists of tweets that have been previously captured and classified as positive or negative.", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "tweets_csv = spark.read.csv('wasb:///data/tweets.csv', inferSchema=True, header=True)\ntweets_csv.show(truncate = False)", "outputs": [], "metadata": {"scrolled": false, "collapsed": false}}, {"source": "### Prepare the Data\nThe features for the classification model will be derived from the tweet text. The label is the sentiment (1 for positive, 0 for negative)", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "data = tweets_csv.select(\"SentimentText\", col(\"Sentiment\").cast(\"Int\").alias(\"label\"))\ndata.show(truncate = False)", "outputs": [], "metadata": {"collapsed": false}}, {"source": "### Split the Data\nIn common with most classification modeling processes, you'll split the data into a set for training, and a set for testing the trained model.", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "splits = data.randomSplit([0.7, 0.3])\ntrain = splits[0]\ntest = splits[1].withColumnRenamed(\"label\", \"trueLabel\")\ntrain_rows = train.count()\ntest_rows = test.count()\nprint \"Training Rows:\", train_rows, \" Testing Rows:\", test_rows", "outputs": [], "metadata": {"collapsed": false}}, {"source": "### Define the Pipeline\nThe pipeline for the model consist of the following stages:\n- A Tokenizer to split the tweets into individual words.\n- A StopWordsRemover to remove common words such as \"a\" or \"the\" that have little predictive value.\n- A HashingTF class to generate numeric vectors from the text values.\n- A LogisticRegression algorithm to train a binary classification model.", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "tokenizer = Tokenizer(inputCol=\"SentimentText\", outputCol=\"SentimentWords\")\nswr = StopWordsRemover(inputCol=tokenizer.getOutputCol(), outputCol=\"MeaningfulWords\")\nhashTF = HashingTF(inputCol=swr.getOutputCol(), outputCol=\"features\")\nlr = LogisticRegression(labelCol=\"label\", featuresCol=\"features\", maxIter=10, regParam=0.01)\npipeline = Pipeline(stages=[tokenizer, swr, hashTF, lr])", "outputs": [], "metadata": {"scrolled": false, "collapsed": false}}, {"source": "### Run the Pipeline as an Estimator\nThe pipeline itself is an estimator, and so it has a **fit** method that you can call to run the pipeline on a specified DataFrame. In this case, you will run the pipeline on the training data to train a model. ", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "piplineModel = pipeline.fit(train)\nprint \"Pipeline complete!\"", "outputs": [], "metadata": {"scrolled": false, "collapsed": false}}, {"source": "### Test the Pipeline Model\nThe model produced by the pipeline is a transformer that will apply all of the stages in the pipeline to a specified DataFrame and apply the trained model to generate predictions. In this case, you will transform the **test** DataFrame using the pipeline to generate label predictions.", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "prediction = piplineModel.transform(test)\npredicted = prediction.select(\"SentimentText\", \"prediction\", \"trueLabel\")\npredicted.show(100, truncate = False)", "outputs": [], "metadata": {"scrolled": false, "collapsed": false}}], "nbformat": 4, "metadata": {"kernelspec": {"display_name": "PySpark", "name": "pysparkkernel", "language": ""}, "language_info": {"mimetype": "text/x-python", "pygments_lexer": "python2", "name": "pyspark", "codemirror_mode": {"version": 2, "name": "python"}}}}